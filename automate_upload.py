import os
import time
import json
import re
import io
import zipfile
import shutil
import cloudscraper
import subprocess
import requests
import sys
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

def process_batch(batch, batch_idx, base_url, process_url, output_dir, valid_extensions):
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±: Ø±ÙØ¹ØŒ Ø§Ù†ØªØ¸Ø§Ø±ØŒ ØªØ­Ù…ÙŠÙ„ØŒ ÙˆÙÙƒ Ø¶ØºØ·.
    """
    scraper = cloudscraper.create_scraper()
    print(f"\n--- [Thread] Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} ({len(batch)} ØµÙˆØ±) ---")
    
    data = {'operation': 'colorize'}
    success = False
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© 5 Ù…Ø±Ø§Øª Ù…Ø¹ Ø§Ù†ØªØ¸Ø§Ø± ØªØµØ§Ø¹Ø¯ÙŠ
    max_retries = 5
    for attempt in range(max_retries):
        files = []
        try:
            for img_path in batch:
                files.append(('images', (os.path.basename(img_path), open(img_path, 'rb'), 'image/jpeg')))
            
            if attempt > 0:
                print(f"[Thread] Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}/{max_retries})...")

            response = scraper.post(process_url, data=data, files=files, timeout=600)
            
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ù„ÙØ§Øª
            for _, file_info in files:
                file_info[1].close()

            if response.status_code == 200:
                result = response.json()
                download_url = result.get('zip_download_url') or result.get('download_url')
                if download_url:
                    if not download_url.startswith('http'):
                        download_url = f"{base_url}{download_url}"
                    
                    print(f"[Thread] ØªÙ… ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} Ø¨Ù†Ø¬Ø§Ø­! Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù…ÙŠÙ„...")
                    r_download = scraper.get(download_url)
                    
                    # ÙÙƒ Ø§Ù„Ø¶ØºØ·
                    with zipfile.ZipFile(io.BytesIO(r_download.content)) as z:
                        for member in z.infolist():
                            if member.filename.lower().endswith(valid_extensions):
                                filename = os.path.basename(member.filename)
                                source = z.open(member)
                                target_path = os.path.join(output_dir, filename)
                                with open(target_path, "wb") as target:
                                    shutil.copyfileobj(source, target)
                    print(f"âœ… [Thread] ØªÙ… Ø­ÙØ¸ ØµÙˆØ± Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx}.")
                    success = True
                    break 
                else:
                    print(f"âš ï¸ [Thread] ÙØ´Ù„ Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx}: Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø±Ø§Ø¨Ø· ØªØ­Ù…ÙŠÙ„.")
            else:
                print(f"âš ï¸ [Thread] ÙØ´Ù„ Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} Ø¨ÙƒÙˆØ¯: {response.status_code}")
            
        except Exception as e:
            print(f"âŒ [Thread] Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} (Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}): {e}")
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ù…Ù„ÙØ§Øª
            for _, file_info in files:
                if not file_info[1].closed:
                    file_info[1].close()
        
        if attempt < max_retries - 1:
            wait_time = 30 * (attempt + 1)  # Ø§Ù†ØªØ¸Ø§Ø± 30ØŒ 60ØŒ 90ØŒ 120 Ø«Ø§Ù†ÙŠØ©...
            print(f"[Thread] Ø§Ù†ØªØ¸Ø§Ø± {wait_time} Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù„Ù„Ø¯ÙØ¹Ø© {batch_idx}...")
            time.sleep(wait_time)

    return success

import threading

HISTORY_FILE = "history.json"
history_lock = threading.Lock()

def load_history():
    if not os.path.exists(HISTORY_FILE):
        return {"scraped": [], "colored": []}
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {"scraped": [], "colored": []}

def save_history(history):
    with history_lock:
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=4)

def add_to_history(category, item):
    """
    category: 'scraped' or 'colored'
    item: identifier (e.g. folder name or path)
    """
    with history_lock:
        history = load_history()
        if item not in history.get(category, []):
            if category not in history:
                history[category] = []
            history[category].append(item)
            # Ø­ÙØ¸ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ù‚ÙÙ„ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ù„Ø£Ù†Ù†Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¯Ø§Ø®Ù„ Ù‚ÙÙ„ (save_history Ù„Ù‡Ø§ Ù‚ÙÙ„ Ø£ÙŠØ¶Ø§Ù‹ØŒ Ù„Ø°Ø§ Ù†ÙƒØªØ¨ Ù…Ø¨Ø§Ø´Ø±Ø©)
            # Ù„ØªØ¬Ù†Ø¨ DeadlockØŒ Ø³Ù†ÙƒØ±Ø± ÙƒÙˆØ¯ Ø§Ù„Ø­ÙØ¸ Ù‡Ù†Ø§ Ø£Ùˆ Ù†Ø¹Ø¯Ù„ save_history
            # Ø§Ù„Ø­Ù„ Ø§Ù„Ø£Ø¨Ø³Ø·: Ù†Ø³Ø® ÙƒÙˆØ¯ Ø§Ù„Ø­ÙØ¸ Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ¯Ø§Ø®Ù„
            with open(HISTORY_FILE, "w", encoding="utf-8") as f:
                json.dump(history, f, ensure_ascii=False, indent=4)

def is_in_history(category, item):
    history = load_history()
    return item in history.get(category, [])

def ensure_server_running():
    """
    ÙŠØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙŠØ¹Ù…Ù„ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† ÙŠØ¹Ù…Ù„ ÙŠÙ‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„Ù‡.
    """
    server_url = "http://127.0.0.1:7860"
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¨Ø´ÙƒÙ„ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ
    current_script_dir = os.path.dirname(os.path.abspath(__file__))
    working_dir = os.path.join(current_script_dir, "Evoars_local", "Evoars-main")
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø± ÙÙŠ Ø¨ÙŠØ¦Ø§Øª Linux
    if not os.path.exists(working_dir):
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£Ø®Ø±Ù‰ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙÙŠ Ù†ÙØ³ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ù…Ø¨Ø§Ø´Ø±Ø©
        working_dir = os.path.join(current_script_dir, "Evoars-main")
        
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø³ÙŠØ±ÙØ±
        response = requests.get(server_url, timeout=2)
        if response.status_code == 200:
            print("âœ… Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„.")
            return True
    except:
        print("ğŸš€ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ø§ ÙŠØ¹Ù…Ù„. Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„Ù‡ Ø§Ù„Ø¢Ù†...")
        
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙÙŠ Ø®Ù„ÙÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
    try:
        log_file_path = os.path.join(current_script_dir, "server_log.txt")
        log_file = open(log_file_path, "a", encoding="utf-8")
        log_file.write(f"\n--- Ø¨Ø¯Ø¡ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„: {datetime.now()} ---\n")
        
        # Ù†Ø³ØªØ®Ø¯Ù… sys.executable Ù„Ø¶Ù…Ø§Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨Ù†ÙØ³ Ù†Ø³Ø®Ø© Ø¨Ø§ÙŠØ«ÙˆÙ† Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        if os.name == 'nt': # Windows
            subprocess.Popen([sys.executable, "app.py"], cwd=working_dir, creationflags=subprocess.CREATE_NEW_CONSOLE)
        else: # Linux / Codespaces
            subprocess.Popen([sys.executable, "app.py"], cwd=working_dir, stdout=log_file, stderr=log_file)
        
        # Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø³ÙŠØ±ÙØ±
        print(f"â³ ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø³ÙŠØ±ÙØ±... (ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø±Ø§Ø¬Ø¹Ø© {os.path.basename(log_file_path)} Ù„Ù„ØªÙØ§ØµÙŠÙ„)")
        max_wait = 30 # 30 Ù…Ø­Ø§ÙˆÙ„Ø© * 5 Ø«ÙˆØ§Ù†ÙŠ = 150 Ø«Ø§Ù†ÙŠØ©
        for i in range(max_wait):
            time.sleep(5)
            try:
                if requests.get(server_url, timeout=2).status_code == 200:
                    print("âœ… ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨Ù†Ø¬Ø§Ø­!")
                    return True
            except:
                print(f"[{i+1}/{max_wait}] ÙÙŠ Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ø³ÙŠØ±ÙØ±...")
        
        print("âŒ ÙØ´Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")
        return False
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ±: {e}")
        return False

def colorize_chapter(source_dir, output_dir):
    """
    ØªÙ‚ÙˆÙ… Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ø¨Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ù…Ù† Ù…Ø¬Ù„Ø¯ Ù…Ø¹ÙŠÙ† Ù„ØªÙ„ÙˆÙŠÙ†Ù‡Ø§ Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ.
    ØªØ³ØªÙÙŠØ¯ Ù…Ù† history.json Ù„ØªØ®Ø·ÙŠ Ù…Ø§ ØªÙ… Ø¥Ù†Ø¬Ø§Ø²Ù‡.
    """
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø£ÙˆÙ„Ø§Ù‹
    ensure_server_running()
    
    chapter_name = os.path.basename(source_dir)
    # Ù…ÙØªØ§Ø­ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„ÙØµÙ„ ÙÙ‚Ø·.
    # Ù„Ù†ØªÙÙ‚ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… "Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯" Ù„ÙŠÙƒÙˆÙ† Ù…Ø­Ù…ÙˆÙ„Ø§Ù‹ØŒ Ø£Ùˆ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ø³Ø¨ÙŠ.
    # Ø¨Ù…Ø§ Ø£Ù† Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù‚Ø¯ ØªØªØºÙŠØ±ØŒ Ø§Ø³Ù… Ø§Ù„ÙØµÙ„ "Jujutsu Kaisen/ÙØµÙ„ Ø±Ù‚Ù… X" Ù‡Ùˆ Ø§Ù„Ø£ÙØ¶Ù„.
    # Ù„ÙƒÙ† source_dir Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù…Ø·Ù„Ù‚Ø§Ù‹. Ø³Ù†Ø³ØªØ®Ø¯Ù… "Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¨/Ø§Ø³Ù… Ø§Ù„ÙØµÙ„".
    
    try:
        parent = os.path.basename(os.path.dirname(source_dir))
        identifier = f"{parent}/{chapter_name}"
    except:
        identifier = chapter_name

    if is_in_history("colored", identifier):
        print(f"â© [ØªØ®Ø·ÙŠ] Ø§Ù„ÙØµÙ„ {identifier} ØªÙ… ØªÙ„ÙˆÙŠÙ†Ù‡ Ø³Ø§Ø¨Ù‚Ø§Ù‹ Ø­Ø³Ø¨ Ø§Ù„Ø³Ø¬Ù„.")
        return True

    if not os.path.exists(source_dir):
        print(f"Ø®Ø·Ø£: Ø§Ù„Ù…Ø¬Ù„Ø¯ {source_dir} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
        return False
    
    # ... Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† output_dir
    if not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    valid_extensions = ('.jpg', '.jpeg', '.png', '.webp')
    image_files = [os.path.join(source_dir, f) for f in os.listdir(source_dir) if f.lower().endswith(valid_extensions)]
    
    if not image_files:
        print(f"ØªØ­Ø°ÙŠØ±: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£ÙŠ ØµÙˆØ± ÙÙŠ {source_dir}")
        return False

    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø³Ø¨Ù‚Ø§Ù‹ (Fallback System)
    # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¬Ù„Ø¯ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØµÙˆØ±ØŒ Ù†Ø¹ØªØ¨Ø±Ù‡ Ù…ÙƒØªÙ…Ù„Ø§Ù‹ Ù„ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª
    if os.path.exists(output_dir):
        existing_colored_images = [f for f in os.listdir(output_dir) if f.lower().endswith(valid_extensions)]
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¹Ø¯Ø¯ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…Ù„ÙˆÙ†Ø© ÙŠØ³Ø§ÙˆÙŠ Ø£Ùˆ Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„ØµÙˆØ± Ø§Ù„Ø£ØµÙ„ÙŠØ© (Ø£Ùˆ Ù‚Ø±ÙŠØ¨ Ù…Ù†Ù‡Ø§)
        if len(existing_colored_images) >= len(image_files):
            print(f"â© [ØªØ®Ø·ÙŠ] Ø§Ù„ÙØµÙ„ {identifier} Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ù‚Ø±Øµ ({len(existing_colored_images)} ØµÙˆØ±Ø©).")
            # Ù†Ø¶ÙŠÙÙ‡ Ù„Ù„Ø³Ø¬Ù„ Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„
            add_to_history("colored", identifier)
            return True
        elif len(existing_colored_images) > 0:
             print(f"âš ï¸ Ø§Ù„ÙØµÙ„ {identifier} Ù…ÙˆØ¬ÙˆØ¯ Ø¬Ø²Ø¦ÙŠØ§Ù‹ ({len(existing_colored_images)}/{len(image_files)}). Ø³ÙŠØªÙ… Ø§Ø³ØªÙƒÙ…Ø§Ù„Ù‡...")
             # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ†Ù†Ø§ ØªØµÙÙŠØ© image_files Ù„Ø§Ø³ØªØ¨Ø¹Ø§Ø¯ Ù…Ø§ ØªÙ… ØªÙ„ÙˆÙŠÙ†Ù‡
             image_files = [f for f in image_files if os.path.basename(f) not in existing_colored_images]
             if not image_files:
                 print(f"â© [ØªØ®Ø·ÙŠ] Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ÙØµÙ„ {identifier} Ù…ÙˆØ¬ÙˆØ¯Ø©.")
                 add_to_history("colored", identifier)
                 return True

    # Ø³Ù†Ù…Ø¶ÙŠ ÙÙŠ Ø§Ù„ØªÙ„ÙˆÙŠÙ†.

    # ÙØ±Ø² Ø§Ù„ØµÙˆØ±
    image_files.sort(key=lambda x: int(re.search(r'(\d+)', os.path.basename(x)).group(1)) if re.search(r'(\d+)', os.path.basename(x)) else 0)
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±
    batch_size = 3
    batches = [image_files[i:i + batch_size] for i in range(0, len(image_files), batch_size)]
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ØªÙ„ÙˆÙŠÙ† Ø§Ù„ÙØµÙ„: {identifier}")
    print(f"ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªØ³Ù„Ø³Ù„Ø© (Ø®Ø· ÙˆØ§Ø­Ø¯) Ù„Ø¶Ù…Ø§Ù† Ø£Ù‚ØµÙ‰ Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ù„Ù„Ø³ÙŠØ±ÙØ±...")

    base_url = "http://127.0.0.1:7860"
    process_url = f"{base_url}/process"
    
    success_all = True
    
    # 1 worker only to prevent server overload
    with ThreadPoolExecutor(max_workers=1) as executor:
        futures = {executor.submit(process_batch, batch, idx, base_url, process_url, output_dir, valid_extensions): idx for idx, batch in enumerate(batches, 1)}
        
        for future in as_completed(futures):
            batch_idx = futures[future]
            try:
                if not future.result():
                    success_all = False
                    print(f"âŒ ÙØ´Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx} Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹.")
            except Exception as exc:
                print(f"âŒ Ø­Ø¯Ø« Ø§Ø³ØªØ«Ù†Ø§Ø¡ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© {batch_idx}: {exc}")
                success_all = False

    if success_all:
        print(f"\nâœ… Ø§ÙƒØªÙ…Ù„ ØªÙ„ÙˆÙŠÙ† ÙƒØ§ÙØ© Ø§Ù„Ø¯ÙØ¹Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ: {output_dir}")
        # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø¹Ù†Ø¯ Ø§Ù„Ù†Ø¬Ø§Ø­ Ø§Ù„ÙƒØ§Ù…Ù„ ÙÙ‚Ø·
        add_to_history("colored", identifier)
    else:
        print(f"\nâš ï¸ Ø§Ù†ØªÙ‡Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹ ÙˆØ¬ÙˆØ¯ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ Ù„Ù† ÙŠØªÙ… Ø§Ù„Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„.")
        
    return success_all

if __name__ == "__main__":
    src = r"C:\Users\abdob\Desktop\mang\source_images"
    out = r"C:\Users\abdob\Desktop\mang\results"
    colorize_chapter(src, out)

